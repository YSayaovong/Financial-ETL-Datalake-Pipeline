{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Install Faker"
      ],
      "metadata": {
        "id": "Znr8riM905Bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Faker\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg9Yf1RT03fm",
        "outputId": "c93796ad-4667-4161-b927-133b9ee4436f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Faker\n",
            "  Downloading faker-37.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from Faker) (2025.2)\n",
            "Downloading faker-37.1.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Faker\n",
            "Successfully installed Faker-37.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mock Data"
      ],
      "metadata": {
        "id": "EYuOjmGt0qTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from faker import Faker\n",
        "from random import choice, uniform\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "\n",
        "# Setup\n",
        "fake = Faker()\n",
        "departments = ['Sales', 'Operations', 'Finance', 'IT', 'Marketing']\n",
        "department_ids = list(range(1, len(departments)+1))\n",
        "months = pd.date_range(start='2024-01-01', periods=12, freq='MS')\n",
        "\n",
        "# Create data folder\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "# 1. departments.csv\n",
        "df_dept = pd.DataFrame({\n",
        "    'department_id': department_ids,\n",
        "    'department_name': departments\n",
        "})\n",
        "df_dept.to_csv(\"data/departments.csv\", index=False)\n",
        "\n",
        "# 2. transactions.csv\n",
        "df_txns = pd.DataFrame([{\n",
        "    'txn_id': i,\n",
        "    'txn_date': fake.date_between(start_date='-12m', end_date='today'),\n",
        "    'amount': round(uniform(-10000, 20000), 2),\n",
        "    'type': choice(['Revenue', 'Expense', 'Adjustment']),\n",
        "    'department_id': choice(department_ids)\n",
        "} for i in range(2000)])\n",
        "df_txns.to_csv(\"data/transactions.csv\", index=False)\n",
        "\n",
        "# 3. invoices.csv\n",
        "df_invoices = pd.DataFrame([{\n",
        "    'invoice_id': i,\n",
        "    'client': fake.company(),\n",
        "    'due_date': fake.date_between(start_date='-6m', end_date='+1m'),\n",
        "    'amount_due': round(uniform(500, 10000), 2),\n",
        "    'paid_date': fake.date_between(start_date='-5m', end_date='today')\n",
        "} for i in range(1000)])\n",
        "df_invoices.to_csv(\"data/invoices.csv\", index=False)\n",
        "\n",
        "# 4. expenses.csv\n",
        "df_expenses = pd.DataFrame([{\n",
        "    'expense_id': i,\n",
        "    'department_id': choice(department_ids),\n",
        "    'category': choice(['Supplies', 'Software', 'Utilities', 'Travel']),\n",
        "    'amount': round(uniform(100, 5000), 2),\n",
        "    'date': fake.date_between(start_date='-12m', end_date='today')\n",
        "} for i in range(800)])\n",
        "df_expenses.to_csv(\"data/expenses.csv\", index=False)\n",
        "\n",
        "# 5. kpi_targets.csv\n",
        "df_kpis = pd.DataFrame([{\n",
        "    'month': m.strftime('%Y-%m'),\n",
        "    'department_id': did,\n",
        "    'kpi_type': choice(['Revenue', 'Profit']),\n",
        "    'target_value': round(uniform(10000, 100000), 2)\n",
        "} for m in months for did in department_ids])\n",
        "df_kpis.to_csv(\"data/kpi_targets.csv\", index=False)\n",
        "\n",
        "print(\"✅ All 5 mock financial datasets generated in /content/data/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOz3o2_20W0_",
        "outputId": "2415c57c-cd27-46fe-f087-5836925fb072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All 5 mock financial datasets generated in /content/data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set Up PySpark"
      ],
      "metadata": {
        "id": "J0HK5Nhw0RI2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Lc0uAi20PXi",
        "outputId": "c549eb55-4294-4b3b-fb22-6031fd3919e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# Install PySpark\n",
        "!pip install pyspark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PySpark ETL Pipeline, Data Cleaning & Aggregation"
      ],
      "metadata": {
        "id": "KHluxaTY1LRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📦 Install PySpark if not already done (run only once per Colab session)\n",
        "!pip install pyspark\n",
        "\n",
        "# 🔧 Import libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import StringType\n",
        "import os\n",
        "\n",
        "# 🧠 Start Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Financial ETL Pipeline\") \\\n",
        "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# 📂 Path to mock CSV data\n",
        "base_path = \"/content/data\"\n",
        "\n",
        "# 🗃️ Load CSVs\n",
        "transactions = spark.read.csv(os.path.join(base_path, \"transactions.csv\"), header=True, inferSchema=True)\n",
        "invoices = spark.read.csv(os.path.join(base_path, \"invoices.csv\"), header=True, inferSchema=True)\n",
        "expenses = spark.read.csv(os.path.join(base_path, \"expenses.csv\"), header=True, inferSchema=True)\n",
        "departments = spark.read.csv(os.path.join(base_path, \"departments.csv\"), header=True, inferSchema=True)\n",
        "kpi_targets = spark.read.csv(os.path.join(base_path, \"kpi_targets.csv\"), header=True, inferSchema=True)\n",
        "\n",
        "# 🧼 Clean and convert date columns\n",
        "transactions = transactions.withColumn(\"txn_date\", to_date(\"txn_date\", \"yyyy-MM-dd\"))\n",
        "invoices = invoices.withColumn(\"due_date\", to_date(\"due_date\", \"yyyy-MM-dd\")) \\\n",
        "                   .withColumn(\"paid_date\", to_date(\"paid_date\", \"yyyy-MM-dd\"))\n",
        "expenses = expenses.withColumn(\"date\", to_date(\"date\", \"yyyy-MM-dd\"))\n",
        "\n",
        "# 🧮 Aggregations\n",
        "transactions_agg = transactions.groupBy(\"department_id\", month(\"txn_date\").alias(\"month\")) \\\n",
        "    .agg(sum(\"amount\").alias(\"net_amount\"))\n",
        "\n",
        "expenses_agg = expenses.groupBy(\"department_id\", month(\"date\").alias(\"month\")) \\\n",
        "    .agg(sum(\"amount\").alias(\"total_expense\"))\n",
        "\n",
        "# ✅ Fix KPI Targets (convert month string to numeric month)\n",
        "kpi_targets = kpi_targets \\\n",
        "    .withColumn(\"month_string\", concat(col(\"month\"), lit(\"-01\")).cast(StringType())) \\\n",
        "    .withColumn(\"month\", month(to_date(\"month_string\", \"yyyy-MM-dd\"))) \\\n",
        "    .drop(\"month_string\")\n",
        "\n",
        "# 🔗 Join everything into a unified summary table\n",
        "summary = kpi_targets \\\n",
        "    .join(transactions_agg, [\"department_id\", \"month\"], \"left\") \\\n",
        "    .join(expenses_agg, [\"department_id\", \"month\"], \"left\") \\\n",
        "    .join(departments, \"department_id\", \"left\") \\\n",
        "    .select(\"month\", \"department_name\", \"kpi_type\", \"target_value\", \"net_amount\", \"total_expense\")\n",
        "\n",
        "# 📊 Preview results\n",
        "summary.show(10)\n",
        "\n",
        "# 💾 Export to CSV\n",
        "output_dir = \"/content/output_kpi_summary\"\n",
        "summary.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(output_dir)\n",
        "\n",
        "# 📦 Zip output folder\n",
        "!zip -r output_kpi_summary.zip output_kpi_summary\n",
        "\n",
        "# 📥 Trigger download\n",
        "from google.colab import files\n",
        "files.download(\"output_kpi_summary.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "FRM8qa6l1NJe",
        "outputId": "e47fe7f5-bb56-4619-eece-69a16137c593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "+-----+---------------+--------+------------+----------+-------------+\n",
            "|month|department_name|kpi_type|target_value|net_amount|total_expense|\n",
            "+-----+---------------+--------+------------+----------+-------------+\n",
            "|    1|          Sales|  Profit|    10905.68|      NULL|         NULL|\n",
            "|    1|     Operations|  Profit|    38088.67|      NULL|         NULL|\n",
            "|    1|        Finance| Revenue|    67522.96|      NULL|         NULL|\n",
            "|    1|             IT|  Profit|    56760.35|      NULL|         NULL|\n",
            "|    1|      Marketing| Revenue|    46883.49|      NULL|         NULL|\n",
            "|    2|          Sales|  Profit|    32824.05|      NULL|         NULL|\n",
            "|    2|     Operations|  Profit|    60488.48|      NULL|         NULL|\n",
            "|    2|        Finance| Revenue|    60548.59|      NULL|         NULL|\n",
            "|    2|             IT|  Profit|    85554.17|      NULL|         NULL|\n",
            "|    2|      Marketing|  Profit|    89826.11|      NULL|         NULL|\n",
            "+-----+---------------+--------+------------+----------+-------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "  adding: output_kpi_summary/ (stored 0%)\n",
            "  adding: output_kpi_summary/part-00000-8831df31-067d-49e4-ab4a-1943d0187773-c000.csv (deflated 64%)\n",
            "  adding: output_kpi_summary/.part-00000-8831df31-067d-49e4-ab4a-1943d0187773-c000.csv.crc (stored 0%)\n",
            "  adding: output_kpi_summary/_SUCCESS (stored 0%)\n",
            "  adding: output_kpi_summary/._SUCCESS.crc (stored 0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6cf4e091-0d2f-46fd-bc89-1be8caf0964e\", \"output_kpi_summary.zip\", 1861)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# 🧱 Rebuild summary using department_id only (NO department_name)\n",
        "summary_clean = kpi_targets \\\n",
        "    .join(transactions_agg, [\"department_id\", \"month\"], \"left\") \\\n",
        "    .join(expenses_agg, [\"department_id\", \"month\"], \"left\") \\\n",
        "    .select(\n",
        "        col(\"month\").cast(\"int\"),\n",
        "        col(\"department_id\").cast(\"int\"),\n",
        "        col(\"kpi_type\").cast(\"string\"),\n",
        "        col(\"target_value\").cast(\"float\"),\n",
        "        col(\"net_amount\").cast(\"float\"),\n",
        "        col(\"total_expense\").cast(\"float\")\n",
        "    )\n",
        "\n",
        "# 💾 Save to new output folder\n",
        "summary_clean.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(\"/content/output_snowflake_final\")\n",
        "\n",
        "# 📦 Zip for download\n",
        "!zip -r output_snowflake_final.zip output_snowflake_final\n",
        "\n",
        "# 📥 Download\n",
        "from google.colab import files\n",
        "files.download(\"output_snowflake_final.zip\")\n",
        "\n"
      ],
      "metadata": {
        "id": "DFTqJtx0272f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "17a44ef9-0c85-4a47-d7e7-27535a942bc5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: output_snowflake_final/ (stored 0%)\n",
            "  adding: output_snowflake_final/.part-00000-cd7cedc8-f78f-4cc9-ab30-f315d0840c58-c000.csv.crc (stored 0%)\n",
            "  adding: output_snowflake_final/_SUCCESS (stored 0%)\n",
            "  adding: output_snowflake_final/._SUCCESS.crc (stored 0%)\n",
            "  adding: output_snowflake_final/part-00000-cd7cedc8-f78f-4cc9-ab30-f315d0840c58-c000.csv (deflated 60%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_46752e5e-44ee-4e1f-8a9d-e4e12efcad41\", \"output_snowflake_final.zip\", 1805)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-UnZAL1y9Lxx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}